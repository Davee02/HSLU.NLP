{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47b1b6f",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "In this exercise, we will look at some basic functionality of PyTorch. Your are free to use other DL frameworks for your exercises and your project. However, the master solutions and code examples will be in PyTorch.\n",
    "\n",
    "The [PyTorch documentation](https://pytorch.org/docs/stable/index.html) offers information on its functionality. A lot of the time, your specific question will also have been asked on the [PyTorch Forum](https://discuss.pytorch.org/), often with competent answers by the core developers (Google will find the relevant thread for you).\n",
    "\n",
    "First, we have to install PyTorch. We will install the basic version for this exercise. For your project, if you want to run on a GPU, you'll have to make sure to have a PyTorch version installed that is compatible with the CUDA version of your NVIDIA drivers. PyTorch has an [installation guide](https://pytorch.org/get-started/locally/) that will help you with getting the right version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a1efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U numpy\n",
    "# %pip install ipywidgets \n",
    "# %pip install torch --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c05320f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec5791",
   "metadata": {},
   "source": [
    "## Tensor operations\n",
    "Most of PyTorch's operations have the same name as in NumPy. The basic object for storing data is the `torch.tensor`, the equivalent of the `np.array`. With the help of the [Tensor tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html), do the following:\n",
    "\n",
    "- Create a `torch.tensor` with the elements `[[1, 2], [3, 4]]`\n",
    "- Create a tensor of ones/zeros with the same shape and dtype\n",
    "- Create a random tensor of the same shape\n",
    "- Print the tensor's shape, data type and device\n",
    "- Try to move it to the GPU\n",
    "- For Mac users: Try to move it to [MPS](https://pytorch.org/docs/stable/notes/mps.html)\n",
    "- Check out indexing/slicing operations, and how you can assign values to a slice.\n",
    "- Combine tensors with `torch.cat` and `torch.stack`. What are the differences?\n",
    "- Multiply tensors, element-wise and with matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90229fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([2, 2])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n",
      "Device of cuda tensor: cuda:0\n",
      "tensor([[1., 0.],\n",
      "        [3., 0.]])\n",
      "tensor([[1., 0.],\n",
      "        [5., 5.]])\n",
      "torch.cat with dim=1\n",
      "tensor([[1., 0., 1., 0., 1., 0.],\n",
      "        [5., 5., 5., 5., 5., 5.]])\n",
      "torch.cat with dim=0\n",
      "tensor([[1., 0.],\n",
      "        [5., 5.],\n",
      "        [1., 0.],\n",
      "        [5., 5.],\n",
      "        [1., 0.],\n",
      "        [5., 5.]])\n",
      "torch.stack\n",
      "tensor([[[1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[5., 5.],\n",
      "         [5., 5.],\n",
      "         [5., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "\n",
    "x_ones = torch.ones_like(x, dtype=x.dtype)\n",
    "x_zeroes = torch.zeros_like(x, dtype=x.dtype)\n",
    "x_random = torch.rand_like(x, dtype=x.dtype)\n",
    "\n",
    "print(f\"Shape of tensor: {x.shape}\")\n",
    "print(f\"Datatype of tensor: {x.dtype}\")\n",
    "print(f\"Device tensor is stored on: {x.device}\")\n",
    "\n",
    "x_cuda = x.to(\"cuda\")\n",
    "print(f\"Device of cuda tensor: {x_cuda.device}\")\n",
    "\n",
    "x[:,1] = 0\n",
    "print(x)\n",
    "\n",
    "x[1:] = 5\n",
    "print(x)\n",
    "\n",
    "# torch.stack: Creates a new dimension while stacking the tensors, the input tensors must have the same shape, returns a new tensor with one more dimension than the input tensors\n",
    "# torch.cat: concatenates tensors along an existing dimension, the tensors must have the same shape except in the dimension along which they are concatenated, does not add a new dimension.\n",
    "print(\"torch.cat with dim=1\")\n",
    "t1 = torch.cat([x, x, x], dim=1)\n",
    "print(t1)\n",
    "\n",
    "print(\"torch.cat with dim=0\")\n",
    "t2 = torch.cat([x, x, x], dim=0)\n",
    "print(t2)\n",
    "\n",
    "print(\"torch.stack\")\n",
    "t3 = torch.stack([x, x, x], dim=1)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36d91f",
   "metadata": {},
   "source": [
    "## Neural Network Basics\n",
    "Solve the followings tasks with the help of the [Neural networks tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
    "\n",
    "The `nn.Module` is the basic class for layers, networks and models. All parameters of an `nn.Module` are automatically discovered by PyTorch and updated by back-propagation.\n",
    "\n",
    "First, define a neural network (as a subclass of `nn.Module`) with two linear layers and a ReLU non-linearity in between. Make the input, output, and inner dimensions parameters of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5284525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66e191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self, input_dim, inner_dim, output_dim):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.fc1 = nn.Linear(input_dim, inner_dim)\n",
    "    self.fc2 = nn.Linear(inner_dim, output_dim)\n",
    "\n",
    "  def forward(self, input):\n",
    "    out = self.relu(self.fc1(input))\n",
    "    out = self.fc2(out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a44cdced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (relu): ReLU()\n",
      "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (fc2): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = 10\n",
    "inner_dim = 20\n",
    "output_dim  = 5\n",
    "\n",
    "model = Net(input_dim=input_dim, inner_dim=inner_dim, output_dim=output_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eae143",
   "metadata": {},
   "source": [
    "Move the entire network to the GPU/MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f976d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  model = model.to(\"cuda\")\n",
    "else:\n",
    "  print(\"CUDA is not available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22867b",
   "metadata": {},
   "source": [
    "Print the parameters of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77e3383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "fc1.weight torch.Size([20, 10])\n",
      "fc1.bias torch.Size([20])\n",
      "fc2.weight torch.Size([5, 20])\n",
      "fc2.bias torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "print(len(params))\n",
    "for name, params in model.named_parameters():\n",
    "  print(name, params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f403132",
   "metadata": {},
   "source": [
    "Run a single forward-pass with a random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3370725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "tensor([[-0.2815, -0.3024, -0.1247, -0.0754,  0.2216],\n",
      "        [-0.4789, -0.2851,  0.0423, -0.0122,  0.1430],\n",
      "        [-0.6411, -0.3181, -0.0855, -0.2721, -0.0074]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "\n",
    "input = torch.randn(batch_size, input_dim).to(\"cuda\")\n",
    "out = model(input)\n",
    "\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d2cb7",
   "metadata": {},
   "source": [
    "Define a `nn.MSELoss` and a random target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd1983de",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # Mean Squared Error\n",
    "target = torch.randn(batch_size, output_dim, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39785fbe",
   "metadata": {},
   "source": [
    "Compute the loss and run backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53d5cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6147, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(out, target)\n",
    "print(loss)\n",
    "model.zero_grad()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278bd02",
   "metadata": {},
   "source": [
    "Update the parameters of your network with a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fe16c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.data = param.data - (param.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927bd19f",
   "metadata": {},
   "source": [
    "Use the `AdamOptimizer` instead to update your parameters (see the [torch.optim documentation](https://pytorch.org/docs/stable/optim.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "054db4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "output = model(input)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step() # updates the model's parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
