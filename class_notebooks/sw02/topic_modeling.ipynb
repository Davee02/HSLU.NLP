{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d81604-025d-4fe1-a130-6a978f5ba135",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "In this exercise, we will do topic modeling with gensim. Use the [topics and transformations tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html) as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e45876ae-0f77-4bf8-8da4-b18618005327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0afb6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6efd1",
   "metadata": {},
   "source": [
    "For tokenizing words and stopword removal, download the NLTK punkt tokenizer and stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edf524f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/david/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/david/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84f40-20bf-47da-b0b4-a0ff28f9b5cd",
   "metadata": {},
   "source": [
    "First, we load the [Lee Background Corpus](https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf) included with gensim that contains 300 news articles of the Australian Broadcasting Corporation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24d72e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "train_file = datapath('lee_background.cor')\n",
    "articles_orig = open(train_file).read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2e56f",
   "metadata": {},
   "source": [
    "Preprocess the text by lowercasing, removing stopwords, stemming, and removing rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88a870af-9f6b-43ea-940f-558e9a21bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:31:55,565 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2025-02-27 12:31:55,593 : INFO : built Dictionary<7349 unique tokens: [\"'ve\", ',', '.', '100', '4:00pm']...> from 300 documents (total 40467 corpus positions)\n",
      "2025-02-27 12:31:55,594 : INFO : Dictionary lifecycle event {'msg': 'built Dictionary<7349 unique tokens: [\"\\'ve\", \\',\\', \\'.\\', \\'100\\', \\'4:00pm\\']...> from 300 documents (total 40467 corpus positions)', 'datetime': '2025-02-27T12:31:55.594628', 'gensim': '4.3.3', 'python': '3.9.21 (main, Dec 11 2024, 16:24:11) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'created'}\n",
      "2025-02-27 12:31:55,602 : INFO : discarding 3829 tokens: [(',', 294), ('.', 300), ('associated', 1), ('burn', 1), ('claire', 1), ('cranebrook', 1), ('deterioration', 1), ('directions', 1), ('falls', 1), ('finger', 1)]...\n",
      "2025-02-27 12:31:55,602 : INFO : keeping 3520 tokens which were in no less than 2 and no more than 150 (=50.0%) documents\n",
      "2025-02-27 12:31:55,606 : INFO : resulting dictionary: Dictionary<3520 unique tokens: [\"'ve\", '100', '4:00pm', '500', '60']...>\n"
     ]
    }
   ],
   "source": [
    "# define stopword list\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords = stopwords | {'\\\"', '\\'', '\\'\\'', '`', '``', '\\'s'}\n",
    "\n",
    "# initialize stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def preprocess(article, stem=False):\n",
    "    # tokenize\n",
    "    article = nltk.word_tokenize(article)\n",
    "\n",
    "    # lowercase all words\n",
    "    article = [word.lower() for word in article]\n",
    "\n",
    "    # remove stopwords\n",
    "    article = [word for word in article if word not in stopwords]\n",
    "\n",
    "    # optional: stem\n",
    "    if stem:\n",
    "        article = [stemmer.stem(word) for word in article]\n",
    "    return article\n",
    "\n",
    "articles = [preprocess(article) for article in articles_orig]\n",
    "\n",
    "# create the dictionary and corpus objects that gensim uses for topic modeling\n",
    "dictionary = gensim.corpora.Dictionary(articles)\n",
    "\n",
    "# remove words that occur in less than 2 documents, or more than 50% of documents\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5)\n",
    "temp = dictionary[0]  # load the dictionary by calling it once\n",
    "corpus_bow = [dictionary.doc2bow(article) for article in articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ae61a",
   "metadata": {},
   "source": [
    "\n",
    "Now we create a TF-IDF model and transform the corpus into TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fab13db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:31:55,631 : INFO : collecting document frequencies\n",
      "2025-02-27 12:31:55,632 : INFO : PROGRESS: processing document #0\n",
      "2025-02-27 12:31:55,643 : INFO : TfidfModel lifecycle event {'msg': 'calculated IDF weights for 300 documents and 3520 features (22934 matrix non-zeros)', 'datetime': '2025-02-27T12:31:55.643612', 'gensim': '4.3.3', 'python': '3.9.21 (main, Dec 11 2024, 16:24:11) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'initialize'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 7), (42, 1), (43, 1), (44, 1), (45, 3), (46, 1), (47, 1), (48, 2), (49, 2), (50, 3), (51, 3), (52, 1), (53, 2), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 2), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 8), (73, 1), (74, 1), (75, 1), (76, 2), (77, 1), (78, 1), (79, 2), (80, 1), (81, 1), (82, 3), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 5), (90, 1), (91, 2), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 3), (99, 1), (100, 1), (101, 3), (102, 1), (103, 1), (104, 1), (105, 4), (106, 2), (107, 1), (108, 1), (109, 1), (110, 1)]\n",
      "[(0, 0.045163832296308125), (1, 0.049004990699027966), (2, 0.09398031720792203), (3, 0.06797874731615453), (4, 0.08637534553463991), (5, 0.10158528888120417), (6, 0.058872481173046734), (7, 0.045871696227162966), (8, 0.04660732651093343), (9, 0.03476708703034139), (10, 0.09174339245432593), (11, 0.06379342938648586), (12, 0.08097953226203827), (13, 0.08637534553463991), (14, 0.06576958891547403), (15, 0.05748249959948285), (16, 0.07679421433236962), (17, 0.09398031720792203), (18, 0.04197717742438698), (19, 0.06379342938648586), (20, 0.09398031720792203), (21, 0.07679421433236962), (22, 0.08097953226203827), (23, 0.058872481173046734), (24, 0.05497796237027076), (25, 0.05497796237027076), (26, 0.07337456058875615), (27, 0.05497796237027076), (28, 0.08637534553463991), (29, 0.058872481173046734), (30, 0.06200577564491172), (31, 0.08637534553463991), (32, 0.09398031720792203), (33, 0.047372990696988616), (34, 0.07048328454536662), (35, 0.09398031720792203), (36, 0.09398031720792203), (37, 0.07679421433236962), (38, 0.06379342938648586), (39, 0.09398031720792203), (40, 0.05276880396959025), (41, 0.3161468260741569), (42, 0.06576958891547403), (43, 0.06576958891547403), (44, 0.04197717742438698), (45, 0.18601732693473516), (46, 0.08637534553463991), (47, 0.09398031720792203), (48, 0.17275069106927982), (49, 0.15358842866473923), (50, 0.1973087667464221), (51, 0.19138028815945754), (52, 0.06379342938648586), (53, 0.18796063441584407), (54, 0.07679421433236962), (55, 0.053840876780419114), (56, 0.07679421433236962), (57, 0.07679421433236962), (58, 0.08637534553463991), (59, 0.043187672767319954), (60, 0.13595749463230905), (61, 0.07048328454536662), (62, 0.06797874731615453), (63, 0.043187672767319954), (64, 0.08637534553463991), (65, 0.04448171465359908), (66, 0.049877527926200725), (67, 0.07337456058875615), (68, 0.05175471008582299), (69, 0.029876861457627475), (70, 0.043823535964961836), (71, 0.07337456058875615), (72, 0.1663540992526395), (73, 0.048171245973727274), (74, 0.09398031720792203), (75, 0.06200577564491172), (76, 0.04274284161044218), (77, 0.07337456058875615), (78, 0.06037377564287238), (79, 0.18796063441584407), (80, 0.09398031720792203), (81, 0.06379342938648586), (82, 0.23038264299710884), (83, 0.05618845771320373), (84, 0.08097953226203827), (85, 0.06379342938648586), (86, 0.07048328454536662), (87, 0.053840876780419114), (88, 0.06797874731615453), (89, 0.14342796675805272), (90, 0.07679421433236962), (91, 0.10995592474054151), (92, 0.06379342938648586), (93, 0.03976801902370649), (94, 0.0360042057531442), (95, 0.06797874731615453), (96, 0.07679421433236962), (97, 0.058872481173046734), (98, 0.11930405707111948), (99, 0.07679421433236962), (100, 0.03050212495565461), (101, 0.18601732693473516), (102, 0.05618845771320373), (103, 0.058872481173046734), (104, 0.08097953226203827), (105, 0.17529414385984735), (106, 0.11237691542640746), (107, 0.045871696227162966), (108, 0.08097953226203827), (109, 0.06037377564287238), (110, 0.03398546693692743)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "\n",
    "tfidf = models.TfidfModel(corpus_bow)\n",
    "corpus_tfidf = tfidf[corpus_bow]\n",
    "\n",
    "print(corpus_bow[0])\n",
    "print(corpus_tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24df8cb",
   "metadata": {},
   "source": [
    "Now we train an [LDA model](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html) with 10 topics on the TF-IDF corpus. Save it to a variable `model_lda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ded6b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:31:55,656 : INFO : using symmetric alpha at 0.1\n",
      "2025-02-27 12:31:55,658 : INFO : using symmetric eta at 0.1\n",
      "2025-02-27 12:31:55,660 : INFO : using serial LDA version on this node\n",
      "2025-02-27 12:31:55,664 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 300 documents, updating model once every 300 documents, evaluating perplexity every 300 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2025-02-27 12:31:55,666 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2025-02-27 12:31:55,814 : INFO : -27.008 per-word bound, 134934897.8 perplexity estimate based on a held-out corpus of 300 documents with 2210 words\n",
      "2025-02-27 12:31:55,815 : INFO : PROGRESS: pass 0, at document #300/300\n",
      "2025-02-27 12:31:55,902 : INFO : topic #2 (0.100): 0.002*\"qantas\" + 0.002*\"workers\" + 0.002*\"afghanistan\" + 0.002*\"hewitt\" + 0.002*\"industrial\" + 0.001*\"afghan\" + 0.001*\"agreement\" + 0.001*\"britain\" + 0.001*\"maintenance\" + 0.001*\"commission\"\n",
      "2025-02-27 12:31:55,904 : INFO : topic #1 (0.100): 0.002*\"union\" + 0.001*\"dr\" + 0.001*\"fire\" + 0.001*\"centre\" + 0.001*\"gambier\" + 0.001*\"commission\" + 0.001*\"india\" + 0.001*\"labor\" + 0.001*\"aircraft\" + 0.001*\"know\"\n",
      "2025-02-27 12:31:55,905 : INFO : topic #4 (0.100): 0.002*\"fire\" + 0.002*\"firefighters\" + 0.002*\"israeli\" + 0.002*\"palestinian\" + 0.002*\"people\" + 0.002*\"company\" + 0.001*\"suicide\" + 0.001*\"sharon\" + 0.001*\"pacific\" + 0.001*\"mr\"\n",
      "2025-02-27 12:31:55,906 : INFO : topic #7 (0.100): 0.002*\"qantas\" + 0.002*\"report\" + 0.002*\"workers\" + 0.002*\"radio\" + 0.001*\"new\" + 0.001*\"abuse\" + 0.001*\"christmas\" + 0.001*\"child\" + 0.001*\"people\" + 0.001*\"company\"\n",
      "2025-02-27 12:31:55,908 : INFO : topic #6 (0.100): 0.002*\"mr\" + 0.001*\"arafat\" + 0.001*\"$\" + 0.001*\"new\" + 0.001*\"zimbabwe\" + 0.001*\"giuliani\" + 0.001*\"year\" + 0.001*\"hih\" + 0.001*\"afp\" + 0.001*\"nauru\"\n",
      "2025-02-27 12:31:55,908 : INFO : topic diff=5.825825, rho=1.000000\n",
      "2025-02-27 12:31:55,910 : INFO : LdaModel lifecycle event {'msg': 'trained LdaModel<num_terms=3520, num_topics=10, decay=0.5, chunksize=2000> in 0.25s', 'datetime': '2025-02-27T12:31:55.910501', 'gensim': '4.3.3', 'python': '3.9.21 (main, Dec 11 2024, 16:24:11) \\n[GCC 11.2.0]', 'platform': 'Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model_lda = LdaModel(\n",
    "    corpus=corpus_tfidf,\n",
    "    id2word=id2word,\n",
    "    num_topics=num_topics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91845654",
   "metadata": {},
   "source": [
    "Let's inspect the first 5 topics of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca3a357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:31:55,921 : INFO : topic #0 (0.100): 0.002*\"alliance\" + 0.002*\"northern\" + 0.001*\"test\" + 0.001*\"bill\" + 0.001*\"taliban\" + 0.001*\"afghanistan\" + 0.001*\"mr\" + 0.001*\"palestinian\" + 0.001*\"interim\" + 0.001*\"us\"\n",
      "2025-02-27 12:31:55,923 : INFO : topic #3 (0.100): 0.002*\"detainees\" + 0.001*\"reid\" + 0.001*\"stage\" + 0.001*\"palestinian\" + 0.001*\"road\" + 0.001*\"human\" + 0.001*\"government\" + 0.001*\"mr\" + 0.001*\"timor\" + 0.001*\"south\"\n",
      "2025-02-27 12:31:55,925 : INFO : topic #6 (0.100): 0.002*\"mr\" + 0.001*\"arafat\" + 0.001*\"$\" + 0.001*\"new\" + 0.001*\"zimbabwe\" + 0.001*\"giuliani\" + 0.001*\"year\" + 0.001*\"hih\" + 0.001*\"afp\" + 0.001*\"nauru\"\n",
      "2025-02-27 12:31:55,927 : INFO : topic #8 (0.100): 0.003*\"palestinian\" + 0.002*\"man\" + 0.002*\"hamas\" + 0.002*\"israeli\" + 0.002*\"india\" + 0.002*\"melbourne\" + 0.002*\"say\" + 0.002*\"security\" + 0.001*\"gaza\" + 0.001*\"club\"\n",
      "2025-02-27 12:31:55,928 : INFO : topic #5 (0.100): 0.002*\"test\" + 0.002*\"south\" + 0.002*\"lee\" + 0.002*\"bowler\" + 0.002*\"virgin\" + 0.002*\"palestinian\" + 0.001*\"match\" + 0.001*\"new\" + 0.001*\"mr\" + 0.001*\"macgill\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"alliance\" + 0.002*\"northern\" + 0.001*\"test\" + 0.001*\"bill\" + 0.001*\"taliban\" + 0.001*\"afghanistan\" + 0.001*\"mr\" + 0.001*\"palestinian\" + 0.001*\"interim\" + 0.001*\"us\"'),\n",
       " (3,\n",
       "  '0.002*\"detainees\" + 0.001*\"reid\" + 0.001*\"stage\" + 0.001*\"palestinian\" + 0.001*\"road\" + 0.001*\"human\" + 0.001*\"government\" + 0.001*\"mr\" + 0.001*\"timor\" + 0.001*\"south\"'),\n",
       " (6,\n",
       "  '0.002*\"mr\" + 0.001*\"arafat\" + 0.001*\"$\" + 0.001*\"new\" + 0.001*\"zimbabwe\" + 0.001*\"giuliani\" + 0.001*\"year\" + 0.001*\"hih\" + 0.001*\"afp\" + 0.001*\"nauru\"'),\n",
       " (8,\n",
       "  '0.003*\"palestinian\" + 0.002*\"man\" + 0.002*\"hamas\" + 0.002*\"israeli\" + 0.002*\"india\" + 0.002*\"melbourne\" + 0.002*\"say\" + 0.002*\"security\" + 0.001*\"gaza\" + 0.001*\"club\"'),\n",
       " (5,\n",
       "  '0.002*\"test\" + 0.002*\"south\" + 0.002*\"lee\" + 0.002*\"bowler\" + 0.002*\"virgin\" + 0.002*\"palestinian\" + 0.001*\"match\" + 0.001*\"new\" + 0.001*\"mr\" + 0.001*\"macgill\"')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ce453",
   "metadata": {},
   "source": [
    "We see the 5 topics with the highest importance. For each topic, the 10 most important words are shown, together with their coefficient of \"alignment\" to the topic.\n",
    "\n",
    "## Document Similarity\n",
    "We now use our LDA model to compare the similarity of new documents (*queries*) to documents in our collection.\n",
    "\n",
    "First, create an index of the news articles in our corpus. Use the `MatrixSimilarity` transformation as described in gensim's [similarity queries tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eb44cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:31:55,937 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2025-02-27 12:31:56,069 : INFO : creating matrix with 300 documents and 10 features\n"
     ]
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(model_lda[corpus_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b2c1f",
   "metadata": {},
   "source": [
    "Now, write a function that takes a query string as input and returns the LDA representation for it. Make sure to apply the same preprocessing as we did to the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dabf9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.032822028), (1, 0.032820974), (2, 0.032821283), (3, 0.032839775), (4, 0.032827053), (5, 0.18322982), (6, 0.55416155), (7, 0.03283031), (8, 0.032826815), (9, 0.032820377)]\n"
     ]
    }
   ],
   "source": [
    "def get_lda_representation(query_preprocessed):\n",
    "    query_preprocessed = preprocess(query_preprocessed)\n",
    "    query_bow = dictionary.doc2bow(query_preprocessed)\n",
    "    query_tfidf = tfidf[query_bow]\n",
    "    query_lda = model_lda[query_tfidf]\n",
    "    return query_lda\n",
    "\n",
    "query = \"An earthquake is really dangerous and can kill many people\"\n",
    "print(get_lda_representation(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77753be",
   "metadata": {},
   "source": [
    "Print the top 5 most similar documents, together with their similarities, using your index created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7696f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.9687249064445496, Article: Australia's quicks and opening batsmen have put the side in a dominant position going into day three of the Boxing Day Test match against South Africa at the MCG. Australia is no wicket for 126, only 151 runs shy of South Africa after Andy Bichel earlier starred as the tourists fell for 277. When play was abandoned due to rain a few overs short of scheduled stumps yesterday, Justin Langer was not out 67 and Matthew Hayden 55. The openers went on the attack from the start, with Langer's innings including six fours and Hayden's eight. Earlier, Shaun Pollock and Nantie Haywood launched a vital rearguard action to help South Africa to a respectable first innings total. The pair put on 44 runs for the final wicket to help the tourists to 277. The South Africans had slumped to 9 for 233 through a combination of Australia's good bowling, good fielding and good luck. After resuming at 3 for 89 yesterday morning, the tourists looked to be cruising as Jacques Kallis and Neil McKenzie added 72 without loss. But then Bichel suddenly had them reeling after snatching two wickets in two balls. First he had Jacques Kallis caught behind for 38, although Kallis could consider himself very unlucky as replays showed his bat was a long way from the ball. On the next ball, Bichel snatched a sharp return catch to dismiss Lance Klusener first ball and have a shot at a hat-trick. Bichel missed out on the hat-trick and Mark Boucher and Neil McKenzie again steadied the South African innings, adding 67 before the introduction of part-timer Mark Waugh to the attack paid off for Australia. Waugh removed Boucher for 43, caught by Bichel. Brett Lee then chipped in, trapping McKenzie leg before for 67 with a perfect inswinger. Bichel continued his good day in the field, running out Claude Henderson for 5 with a direct-hit from the in-field. Lee roared in to Allan Donald, bouncing him and then catching the edge with a rising delivery, which Ricky Ponting happily swallowed at third slip to remove the returning paceman for a duck. Bichel did not get his hat-trick but ended with the best figures of the Australian bowlers, after also picking up the final wicket of Nantie Haywood for 14. Lee took 3 for 77 and Glenn McGrath 2 for 66. \n",
      "Similarity: 0.9498894214630127, Article: New Zealand has rewarded Lord of the Rings director Peter Jackson in its New Years Honours list. Jackson, who has spent seven years on filming the Tolkien classic in his home country has been made a companion of the New Zealand Order of Merit. The first of three films employed a cast of over 2,000 and had a budget of $534 million - far and away New Zealand's biggest production ever. There is no chance Jackson himself will become a Lord though - New Zealand's Labour Government last year dropped knighthoods in favour of local honours. \n",
      "Similarity: 0.9493985176086426, Article: Australian's casinos generated a $3.1 billion income in the 2000-2001 financial year. The Australian Bureau of Statistics has found gambling was the biggest money winner for casinos, making up 80 per cent or $2.5 billion of total income. Governments also did well, taking more than $500 million from the casinos for gambling taxes and levies while the 20,000 employees were paid more than $800 million for their work. But despite the expense, the profit for Australian casinos increased by 19 per cent for the year. At the end of June this year, there was almost 11,000 poker and gaming machines and more than 1,000 gaming tables across Australia. \n",
      "Similarity: 0.949041485786438, Article: Australia has linked $10 million of aid to a new agreement with Nauru to accept an extra 400 asylum seekers. The deal means Nauru will take up to 1,200 asylum seekers under Australia's Pacific solution. Foreign Minister Alexander Downer signed the understanding today with Nauru's President Rene Harris. Mr Downer inspected the Nauru camps and says they are are practical and efficient. \"I had a good look at the sanitation, the ablution blocks and thought they were pretty good,\" he said. \"The asylum seekers have various things to do. There are volleyball facilities and soccer facilities. \"Television is available, they can see 21 different channels on TV. \"The catering is good, there are three meals a day provided.\" \n",
      "Similarity: 0.9490114450454712, Article: Several people, believed to be as many as 35, have been shot at a northern Indiana factory in the United States. Police said the person who did the shooting was still inside the building. Preliminary reports suggested a disgruntled employee might be behind the mass shooting at Nu-Wood Decorative Millwork factory at the industrial park in Goshen, which occurred around 3:14pm local time (7:14am AEDT). \"We're hearing as many as 35 have been shot but we can't confirm that,\" said a Goshen police dispatcher. \"We haven't been able to get inside.\" She said the person who fired the shots at the factory near Goshen was still inside the facility. The city is about 200 kilometres east of Chicago. \n"
     ]
    }
   ],
   "source": [
    "query_lda = get_lda_representation(query)\n",
    "sims = index[query_lda]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "for doc_position, doc_score in sims[:5]:\n",
    "    print(f\"Similarity: {doc_score}, Article: {articles_orig[doc_position]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e05dba",
   "metadata": {},
   "source": [
    "Run your code again, now training an LDA model with 100 topics. Do you see a qualitative difference in the top-5 most similar documents?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
